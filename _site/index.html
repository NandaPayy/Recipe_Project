<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>From Ingredients to Minutes: How Nutrition and Complexity Drive Cooking Time | Recipe_Project</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="From Ingredients to Minutes: How Nutrition and Complexity Drive Cooking Time" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="project for DSC 80 at UCSD" />
<meta property="og:description" content="project for DSC 80 at UCSD" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Recipe_Project" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="From Ingredients to Minutes: How Nutrition and Complexity Drive Cooking Time" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"project for DSC 80 at UCSD","headline":"From Ingredients to Minutes: How Nutrition and Complexity Drive Cooking Time","name":"Recipe_Project","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=48d20b173b716d35a94afe0f911f239ffca99bdb">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">From Ingredients to Minutes: How Nutrition and Complexity Drive Cooking Time</h1>
      <h2 class="project-tagline">project for DSC 80 at UCSD</h2>
      
        <a href="https://github.com/NandaPayy/Recipe_Project" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="from-ingredients-to-minutes-how-nutrition-and-complexity-drive-cooking-time">From Ingredients to Minutes: How Nutrition and Complexity Drive Cooking Time</h1>

<p>Authors: Aarshia Gupta (aag022@ucsd.edu) and Nanda Payyappilly (npayyappilly@ucsd.edu)</p>

<hr />

<h2 id="overview">Overview</h2>

<p>This data science project, conducted at UCSD, focuses on predicting whether a recipe has a long or short cooking time based on its <strong>nutritional composition and preparation complexity</strong>. Using a dataset of recipes, we analyze macronutrient balance, sodium, sugar, fat content, calories, and the number of steps to build a classification model that identifies patterns in meal preparation time.</p>

<h2 id="introduction">Introduction</h2>

<p>Food plays a crucial role in daily life, and cooking time is a key factor in meal planning. According to the USDA Economic Research Service, Americans aged 18 and over spend an average of 37 minutes per day on meal preparation. In today’s fast-paced world, many people prioritize quick, convenient meals, sometimes at the expense of nutritional balance. But do healthier, more balanced meals inherently require longer preparation, or can nutritious meals still be made efficiently?</p>

<p><strong>This project explores whether a recipe’s nutritional composition and preparation complexity can predict its cooking duration</strong>. Specifically, we investigate how factors such as macronutrient balance, sodium, sugar, fat content, calorie count, and the number of preparation steps influence whether a recipe falls into the short or long cooking time category. Understanding this relationship can help individuals make <strong>better meal-planning choices</strong>, balancing <strong>nutrition, efficiency, and convenience</strong>.</p>

<p>To conduct this analysis, we utilize a dataset from food.com, which contains thousands of recipes along with detailed nutritional profiles, number of steps, ratings and reviews. Originally collected for research on personalized recipe recommendations (Majumder et al.), this dataset serves as the foundation for our analysis and prediction efforts.</p>

<p>The first dataset, <code class="language-plaintext highlighter-rouge">recipes</code>, consists of 83,782 entries, each representing a unique recipe with 12 recorded attributes, including:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Column</strong></td>
      <td><strong>Description</strong></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">name</code></td>
      <td>Recipe name</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">id</code></td>
      <td>Recipe ID</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">minutes</code></td>
      <td>Minutes to prepare recipe</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">contributor_id</code></td>
      <td>User ID who submitted this recipe</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">submitted</code></td>
      <td>Date recipe was submitted</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">tags</code></td>
      <td>Food.com tags for recipe</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">nutrition</code></td>
      <td>Nutrition information in the form [calories (#), total fat (PDV), sugar (PDV), sodium (PDV), protein(PDV), saturated fat (PDV), carbohydrates (PDV)]; PDV stands for “percentage of daily value”</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">n_steps</code></td>
      <td>Number of steps in recipe</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">steps</code></td>
      <td>Text for recipe steps, in order</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">description</code></td>
      <td>User-provided description</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">ingredients</code></td>
      <td>Text for recipe ingredients</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">n_ingredients</code></td>
      <td>Number of ingredients in recipe</td>
    </tr>
  </tbody>
</table>

<p>The second dataset, <code class="language-plaintext highlighter-rouge">interactions</code>, contains 731,927 entries, where each row corresponds to a user review for a specific recipe, with various rating-related details such as:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Column</strong></td>
      <td><strong>Description</strong></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">user_id</code></td>
      <td>User ID</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">recipe_id</code></td>
      <td>Recipe ID</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">date</code></td>
      <td>Date of interaction</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">rating</code></td>
      <td>Rating given</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">review</code></td>
      <td>Review text</td>
    </tr>
  </tbody>
</table>

<p>Since the dataset did not originally contain a measure of nutritional balance, we created a balance score to quantify how closely a recipe aligns with recommended macronutrient distributions of fat, protein, and carbohydrates. Initially, we focused on balance scores as our primary feature. However, through further analysis, we identified additional attributes that improved model performance. We incorporated features such as sodium, sugar, fat content, total calories, and the number of preparation steps, providing a more comprehensive understanding of how nutritional and procedural complexity relate to cooking time.</p>

<p>To ensure consistency across the dataset, we preprocessed the nutritional values and extracted meaningful indicators of recipe complexity. The most relevant features for our classification task include:</p>

<ul>
  <li><strong>Balance Score</strong>: A calculated metric that measures how well a recipe aligns with recommended macronutrient distributions.</li>
  <li><strong>Calories</strong>: Total energy per serving.</li>
  <li><strong>Sodium &amp; Sugar Content</strong>: Key indicators of recipe composition.</li>
  <li><strong>Saturated Fat &amp; Total Fat</strong>: Measures of fat composition in the recipe.</li>
  <li><strong>Number of Steps</strong>: A procedural complexity metric reflecting recipe preparation difficulty.</li>
</ul>

<p>By building a classification model based on these attributes, we aim to gain insight into how recipe complexity and nutrition correlate with cooking time. This research can help individuals make more informed meal planning decisions by understanding whether certain dietary and procedural characteristics predict longer or shorter preparation times. Additionally, the findings may contribute to future studies exploring the trade-off between nutrition and cooking efficiency, particularly in the context of modern dietary habits.</p>

<hr />

<h2 id="cleaning-and-exploratory-data-analysis">Cleaning and Exploratory Data Analysis</h2>

<p>We conducted the following steps to clean the two dataframes and proceed to the analysis:</p>

<ol>
  <li><strong>Left merged</strong> the recipes and interactions dataset on id and recipe_id in order to match each unique recipe to their corresponding rating and review</li>
  <li>Dropped irrelevant columns, <code class="language-plaintext highlighter-rouge">Unnamed: 0_x</code>, <code class="language-plaintext highlighter-rouge">Unnamed: 0_y</code>, that resulted from the merge</li>
  <li>Checked the <strong>data types</strong> of all the columns in the dataset to ensure the data types make sense for each column
    <ul>
      <li>
        <table>
          <thead>
            <tr>
              <th style="text-align: left">Column</th>
              <th style="text-align: left">Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align: left">name</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">id</td>
              <td style="text-align: left">int64</td>
            </tr>
            <tr>
              <td style="text-align: left">minutes</td>
              <td style="text-align: left">int64</td>
            </tr>
            <tr>
              <td style="text-align: left">contributor_id</td>
              <td style="text-align: left">int64</td>
            </tr>
            <tr>
              <td style="text-align: left">submitted</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">tags</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">nutrition</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">n_steps</td>
              <td style="text-align: left">int64</td>
            </tr>
            <tr>
              <td style="text-align: left">steps</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">description</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">ingredients</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">n_ingredients</td>
              <td style="text-align: left">int64</td>
            </tr>
            <tr>
              <td style="text-align: left">user_id</td>
              <td style="text-align: left">float64</td>
            </tr>
            <tr>
              <td style="text-align: left">recipe_id</td>
              <td style="text-align: left">float64</td>
            </tr>
            <tr>
              <td style="text-align: left">date</td>
              <td style="text-align: left">object</td>
            </tr>
            <tr>
              <td style="text-align: left">rating</td>
              <td style="text-align: left">float64</td>
            </tr>
            <tr>
              <td style="text-align: left">review</td>
              <td style="text-align: left">object</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>For the <code class="language-plaintext highlighter-rouge">rating</code> column, fill all ratings of <strong>0 with np.nan</strong>
    <ul>
      <li>This is because, generally, the rating goes from 1-5 with 1 indicating the lowest and 5 indicating the highest rating. A value of 0 likely indicates a missing rating instead of an actual rating. But, including a 0 could result in a <strong>distortion when conducting statistical analyses</strong> like mean, median, etc. So, np.nan is a more meaningful placeholder.</li>
    </ul>
  </li>
  <li>Added a new column, <code class="language-plaintext highlighter-rouge">average_rating</code>, that contains the <strong>average rating per recipe</strong>
    <ul>
      <li>Each recipe can have different ratings from different users, so to get a better understanding of the rating of the recipe overall, we can take the average of all the ratings.</li>
    </ul>
  </li>
  <li>Converted the nutrition column and extract nutritional values into separate columns of floats
    <ul>
      <li>The <code class="language-plaintext highlighter-rouge">nutrition</code> column contains strings representing lists, so we converted these strings to a proper JSON format and converted them into a DataFrame with <strong>specific nutrition columns</strong> like <code class="language-plaintext highlighter-rouge">calories (#)</code>, <code class="language-plaintext highlighter-rouge">total fat (PDV)</code>, <code class="language-plaintext highlighter-rouge">sugar (PDV)</code>, <code class="language-plaintext highlighter-rouge">sodium (PDV)</code>, <code class="language-plaintext highlighter-rouge">protein (PDV)</code>, <code class="language-plaintext highlighter-rouge">saturated fat (PDV)</code>, and <code class="language-plaintext highlighter-rouge">carbohydrates (PDV)</code>. Then we merged these new columns back into the original merged dataframe.</li>
    </ul>
  </li>
  <li>Dropped recipes where <code class="language-plaintext highlighter-rouge">calories</code> are zero
    <ul>
      <li>We did this because we want to calculate the balance score for each recipe, which involves the proportion of <code class="language-plaintext highlighter-rouge">carbohydrates</code>, <code class="language-plaintext highlighter-rouge">protein</code>, and <code class="language-plaintext highlighter-rouge">fat</code> as well as <code class="language-plaintext highlighter-rouge">calories</code>. When calculating this, we would have calories as the denominator for the proportions, which would result in a <strong>ZeroDivisionError</strong>. The number of rows with calories as 0 was only 102, which is a <strong>small subset</strong> of the entire dataframe, so removing these rows <strong>wouldn’t affect</strong> the analysis.</li>
    </ul>
  </li>
  <li>Imputed <code class="language-plaintext highlighter-rouge">fat</code>, <code class="language-plaintext highlighter-rouge">carbohydrates</code>, and <code class="language-plaintext highlighter-rouge">protein</code> with the median for their respective columns
    <ul>
      <li>We used a SimpleImputer with the <strong>median</strong> strategy to fill missing values in the <code class="language-plaintext highlighter-rouge">total_fat</code>, <code class="language-plaintext highlighter-rouge">carbohydrates</code>, and <code class="language-plaintext highlighter-rouge">protein</code> columns, as missing values would interfere with calculating proportions and balance scores, and the <strong>median is robust to outliers</strong>.</li>
    </ul>
  </li>
  <li>Calculated the proportions of each macronutrient relative to total calories and add new columns <code class="language-plaintext highlighter-rouge">prop_fat</code>, <code class="language-plaintext highlighter-rouge">prop_carbs</code>, <code class="language-plaintext highlighter-rouge">prop_protein</code> to the dataframe
    <ul>
      <li>We calculated the proportions of fat, carbohydrates, and protein relative to total calories using <strong>standard nutritional guidelines</strong>: fat provides 9 calories per gram, while carbs and protein provide 4. The <strong>specific reference values</strong> (78g fat, 275g carbs, 50g protein) represent <strong>daily recommended intakes</strong>. For each macronutrient, we divided the <strong>percentage of macronutrient</strong> by 100, multiplying it by the <strong>recommended grams of macronutrient</strong> and the <strong>calories per gram of macronutrient</strong>, then dividing by the <strong>total calories</strong> in the recipe.</li>
    </ul>
  </li>
  <li>Added <code class="language-plaintext highlighter-rouge">balance_score</code> column to the dataframe
    <ul>
      <li>The “balance score” measures <strong>how closely the proportions align with an ideal macronutrient distribution</strong> (55% carbs, 25% fat, 20% protein), resulting in balance with higher scores. We calculated the <code class="language-plaintext highlighter-rouge">balance_score</code> by summing the absolute differences between each macronutrient proportion and its ideal value (carbs: 0.55, fat: 0.25, protein: 0.20), subtracting this sum from 1 to measure how closely the proportions align with the ideal balance.</li>
    </ul>
  </li>
  <li>Filtered dataset to exclude extreme outliers in the <code class="language-plaintext highlighter-rouge">minutes</code> column
    <ul>
      <li>Here, we computed the <strong>interquartile range (IQR)</strong> for the <code class="language-plaintext highlighter-rouge">minutes</code> column to identify and filter extreme outliers. By defining lower and upper bounds as Q1 − 1.5×IQR and Q3 + 1.5×IQR, we excluded values far outside the typical range. This step is crucial because the minutes column contains  <strong>outliers</strong>, like a maximum of 1,051,200 minutes, which could skew our analysis of how nutrition varies between recipes with short and long cooking times. For our upper bound we got 120 and the lower bound was a negative value, which we considered as 0 minutes, and we filtered our dataset based on these new bounds.</li>
    </ul>
  </li>
  <li>Added <code class="language-plaintext highlighter-rouge">cooking_time_category</code> column to the dataframe
    <ul>
      <li>We categorized recipes as having “short” or “long” cooking times based on whether their cooking time was below or above the <strong>mean of the minutes column</strong> (36.77 minutes). The mean was chosen as the threshold because it provides a central reference point, ensuring a <strong>balanced split between the two categories</strong> for a fair analysis of how nutrition content varies with cooking time. And since we removed the outliers in the previous step, we can ensure that the mean is not affected by outliers.</li>
    </ul>
  </li>
</ol>

<h3 id="result">Result</h3>
<p>Here are the columns of the cleaned dataframe:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">name</th>
      <th style="text-align: right">id</th>
      <th style="text-align: right">minutes</th>
      <th style="text-align: right">calories</th>
      <th style="text-align: right">total_fat</th>
      <th style="text-align: right">protein</th>
      <th style="text-align: right">carbohydrates</th>
      <th style="text-align: right">prop_fat</th>
      <th style="text-align: right">prop_carbs</th>
      <th style="text-align: right">prop_protein</th>
      <th style="text-align: right">balance_score</th>
      <th style="text-align: left">cooking_time_category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1 brownies in the world    best ever</td>
      <td style="text-align: right">333281</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">138.4</td>
      <td style="text-align: right">10</td>
      <td style="text-align: right">3</td>
      <td style="text-align: right">6</td>
      <td style="text-align: right">0.507225</td>
      <td style="text-align: right">0.238439</td>
      <td style="text-align: right">0.0867052</td>
      <td style="text-align: right">0.317919</td>
      <td style="text-align: left">long</td>
    </tr>
    <tr>
      <td style="text-align: left">1 in canada chocolate chip cookies</td>
      <td style="text-align: right">453467</td>
      <td style="text-align: right">45</td>
      <td style="text-align: right">595.1</td>
      <td style="text-align: right">46</td>
      <td style="text-align: right">13</td>
      <td style="text-align: right">26</td>
      <td style="text-align: right">0.542631</td>
      <td style="text-align: right">0.240296</td>
      <td style="text-align: right">0.0873803</td>
      <td style="text-align: right">0.285045</td>
      <td style="text-align: left">long</td>
    </tr>
    <tr>
      <td style="text-align: left">412 broccoli casserole</td>
      <td style="text-align: right">306168</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">194.8</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">22</td>
      <td style="text-align: right">3</td>
      <td style="text-align: right">0.720739</td>
      <td style="text-align: right">1.2423</td>
      <td style="text-align: right">0.0308008</td>
      <td style="text-align: right">-0.332238</td>
      <td style="text-align: left">long</td>
    </tr>
    <tr>
      <td style="text-align: left">millionaire pound cake</td>
      <td style="text-align: right">286009</td>
      <td style="text-align: right">120</td>
      <td style="text-align: right">878.3</td>
      <td style="text-align: right">63</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">39</td>
      <td style="text-align: right">0.503541</td>
      <td style="text-align: right">0.250484</td>
      <td style="text-align: right">0.0888079</td>
      <td style="text-align: right">0.335751</td>
      <td style="text-align: left">long</td>
    </tr>
    <tr>
      <td style="text-align: left">2000 meatloaf</td>
      <td style="text-align: right">475785</td>
      <td style="text-align: right">90</td>
      <td style="text-align: right">267</td>
      <td style="text-align: right">30</td>
      <td style="text-align: right">29</td>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0.788764</td>
      <td style="text-align: right">1.19476</td>
      <td style="text-align: right">0.0149813</td>
      <td style="text-align: right">-0.368539</td>
      <td style="text-align: left">long</td>
    </tr>
  </tbody>
</table>

<h3 id="univariate-analysis">Univariate Analysis</h3>

<p>To analyze the distribution of cooking times in recipes, we examined a box plot before and after removing outliers. Initially, the data contained extreme values, with some recipes reporting cooking durations close to one million minutes, likely due to misentries. These extreme outliers compressed the rest of the data, making it difficult to interpret meaningful patterns as seen below. To address this, we <strong>removed outliers using the Interquartile Range (IQR) method</strong>, allowing us to focus on a more representative range of cooking times.</p>

<iframe src="assets/uni1_fig.html" width="800" height="600" frameborder="0"></iframe>

<p>After removing outliers, the refined box plot below shows that most recipes take between 10 and 60 minutes to prepare, with a median around 30 minutes. The cleaned dataset provides a more accurate view of typical cooking times, making it more reliable for predictive modeling without being skewed by erroneous values.</p>

<iframe src="assets/uni2_fig.html" width="800" height="600" frameborder="0"></iframe>

<h3 id="bivariate-analysis">Bivariate Analysis</h3>

<p>To explore the relationship between nutritional composition and cooking time, we analyzed the average proportions of fat, protein, and carbohydrates across short and long cooking time categories.</p>

<p>From the bar chart shown below, we observe that <strong>long-cooking recipes</strong> tend to have a <strong>slightly higher proportion of fat and carbohydrates</strong> compared to short-cooking recipes, while protein content remains relatively similar across both categories. Additionally, the <strong>balance score</strong>, which measures how closely a recipe aligns with recommended macronutrient distributions, is <strong>slightly higher for long-cooking recipes</strong>.</p>

<p>These findings suggest that nutrient composition may play a role in determining cooking time, with longer recipes potentially involving more ingredients or preparation complexity. However, the differences in proportions are not drastic, indicating that additional factors, such as the number of steps and ingredient complexity, may also contribute to cooking duration.</p>

<iframe src="assets/bivar_fig.html" width="800" height="600" frameborder="0"></iframe>

<h3 id="interesting-aggregates">Interesting Aggregates</h3>

<p>We analyzed the relationship between cooking time and balance score using a grouped table and a visualization of key statistics over time.
The pivot table shown below provides <strong>aggregated statistics</strong> (mean, median, min, max) for the balance score at different cooking times. This helps us observe how the nutritional balance of recipes fluctuates as preparation time increases.</p>

<p>Here are the first few rows from our aggregated pivot table (has a total of 120 rows for 120 minutes):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">minutes</th>
      <th style="text-align: right">mean_balance_score</th>
      <th style="text-align: right">median_balance_score</th>
      <th style="text-align: right">min_balance_score</th>
      <th style="text-align: right">max_balance_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">-0.823702</td>
      <td style="text-align: right">-0.823702</td>
      <td style="text-align: right">-0.823702</td>
      <td style="text-align: right">-0.823702</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0.118668</td>
      <td style="text-align: right">0.0479904</td>
      <td style="text-align: right">-1.32309</td>
      <td style="text-align: right">0.839363</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0.181795</td>
      <td style="text-align: right">0.154448</td>
      <td style="text-align: right">-2.52287</td>
      <td style="text-align: right">0.884065</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">0.161351</td>
      <td style="text-align: right">0.122113</td>
      <td style="text-align: right">-1.36223</td>
      <td style="text-align: right">0.876521</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">0.154164</td>
      <td style="text-align: right">0.20384</td>
      <td style="text-align: right">-2.70683</td>
      <td style="text-align: right">0.872263</td>
    </tr>
  </tbody>
</table>

<p>The second visualization below shows the trends of these statistics over cooking time. By examining these aggregates, we observe that while the <strong>mean and median balance</strong> scores remain relatively <strong>stable</strong> across different cooking times, the <strong>minimum balance</strong> score fluctuates more significantly for longer recipes. This suggests that recipes with very low balance scores can sometimes take longer to prepare. Meanwhile, the <strong>maximum balance score</strong> remains high regardless of cooking duration, indicating that highly balanced meals can be achieved across varying preparation times.</p>

<iframe src="assets/bal_fig.html" width="800" height="600" frameborder="0"></iframe>

<p>These findings help contextualize our classification model by showing general trends in the data, even if they do not necessarily determine a causal relationship. This analysis supports our broader investigation of how nutrition and preparation complexity relate to cooking time.</p>

<hr />

<h2 id="assessment-of-missingness">Assessment of Missingness</h2>

<p>There are three columns in the merged dataset that have a significant amount of missing values. These are <code class="language-plaintext highlighter-rouge">rating</code>, <code class="language-plaintext highlighter-rouge">description</code>, and <code class="language-plaintext highlighter-rouge">review</code>. Due to a significant amount of missingness, we will be analyzing them further.</p>

<h3 id="nmar-analysis">NMAR Analysis</h3>

<p>We believe that the description column might be Not Missing at Random (NMAR) because people who didn’t add a description might be less engaged with the platform, or maybe the recipe is so simple/self-explanatory that they didn’t feel the need to write one. To determine if it’s Missing At Random (MAR), we would need additional data about the user’s activity on the platform like the number of recipes submitted, contribution frequency, information about the recipe like the number of steps, number of ingredients, cooking time (which are provided in our merged dataset), and how familiar the user is with the platform (experienced vs. new users).</p>

<h3 id="missingness-dependency">Missingness Dependency</h3>

<p>We decided to examine the missingness of <code class="language-plaintext highlighter-rouge">rating</code> in the merged dataset by testing the dependency of its missingness. We looked at whether the missingness in the <code class="language-plaintext highlighter-rouge">rating</code> column depends on the column, <code class="language-plaintext highlighter-rouge">n_ingredients</code>, the number of ingredients in a recipe, or the column <code class="language-plaintext highlighter-rouge">minutes</code>, the time it took to prepare a recipe.</p>

<blockquote>
  <h4 id="number-of-ingredients-and-rating"><span><strong><em>Number of Ingredients and Rating</em></strong></span></h4>
</blockquote>

<p><ins><strong>Null Hypothesis</strong></ins>: The missingness of ratings does not depend on the number of ingredients in the recipe.</p>

<p><ins><strong>Alternate Hypothesis</strong></ins>: The missingness of ratings does depend on the number of ingredients in the recipe.</p>

<p><ins><strong>Test Statistic</strong></ins>: The difference in means in the number of ingredients of the distribution of the group without missing ratings and the distribution of the group without missing ratings.</p>

<p><ins><strong>Significance Level</strong></ins>: 0.05</p>

<iframe src="assets/ing_missing.html" width="800" height="600" frameborder="0"></iframe>

<p>We performed a permutation test to evaluate whether the observed difference in means of a column, grouped by a missingness indicator, is statistically significant. By shuffling the <code class="language-plaintext highlighter-rouge">rating</code> column values multiple times (1000 permutations), we built a null distribution of mean differences and calculated the p-value as the proportion of shuffled differences as extreme as the observed difference.</p>

<p>The observed statistic of <strong>0.1607</strong> is indicated by the red vertical line on the distribution. Since the p_value is 0.0, it is less than 0.05, therefore we r<strong>eject the null hypothesis</strong>. The missingness of <code class="language-plaintext highlighter-rouge">rating</code> <strong>does depend on</strong> the <code class="language-plaintext highlighter-rouge">n_ingredients</code>, which is the number of ingredients in a recipe.</p>

<blockquote>
  <h4 id="cooking-minutes-and-rating"><span><strong><em>Cooking Minutes and Rating</em></strong></span></h4>
</blockquote>

<p><ins><strong>Null Hypothesis</strong></ins>: The missingness of ratings does not depend on the cooking minutes in the recipe.</p>

<p><ins><strong>Alternate Hypothesis</strong></ins>: The missingness of ratings does depend on the cooking minutes in the recipe.</p>

<p><ins><strong>Test Statistic</strong></ins>: The difference in means in cooking minutes of the distribution of the group without missing ratings and the distribution of the group without missing ratings.</p>

<p><ins><strong>Significance Level</strong></ins>: 0.05</p>

<iframe src="assets/cooking_kde.html" width="800" height="600" frameborder="0"></iframe>
<p>As seen above, outliers in cooking time make it hard to discern the shapes of the two distributions, so we adjust the scale to examine them more closely which can be seen in the plot below.</p>
<iframe src="assets/scaled_cooking_kde.html" width="800" height="600" frameborder="0"></iframe>

<iframe src="assets/cooking_emp.html" width="800" height="600" frameborder="0"></iframe>

<p>Similar to the previous test, we performed another permutation test by shuffling the <code class="language-plaintext highlighter-rouge">rating</code> column values 1000 times to generate 1000 simulated mean differences between the two distributions based on the test statistic defined above.</p>

<p>The observed statistic is <strong>51.45237</strong> as indicated by the red vertical line on the graph. Since the p-value is <strong>0.12</strong>, which is greater than 0.05, we <strong>fail to reject the null hypothesis</strong>. The missingness of <code class="language-plaintext highlighter-rouge">rating</code> <strong>does not depend on</strong> the cooking time in <code class="language-plaintext highlighter-rouge">minutes</code> of the recipe.</p>

<hr />

<h2 id="hypothesis-testing">Hypothesis Testing</h2>

<p>As mentioned previously, we aim to determine whether recipes with <strong>longer cooking times are more nutritionally balanced than those with shorter cooking times</strong>. To investigate this, we conducted a permutation test with the following hypotheses, test statistic, and significance level.</p>

<p><ins><strong>Null Hypothesis</strong></ins>: There is no significant difference in the average balance score between short and long cooking time recipes.</p>

<p><ins><strong>Alternate Hypothesis</strong></ins>: Recipes with long cooking times have significantly higher balance scores than shorter cooking time recipes.</p>

<p><ins><strong>Test Statistic</strong></ins>: The difference in means of the balance scores between long and short cooking time recipes.</p>

<p><ins><strong>Significance Level</strong></ins>: 0.05</p>

<p>The reason for choosing a permutation test is that we lack information about the population distribution and want to assess whether the observed difference in means between long and short cooking times could occur by chance. A permutation test lets us simulate a null distribution by shuffling cooking time labels and recalculating the test statistic, making no strict assumptions about the data.</p>

<p>We hypothesized that longer cooking times may allow for the preparation of more <strong>complex</strong> meals, as they often involve a wider variety of ingredients, which could result in a better balance of macronutrients. For example, stews, soups, or baked dishes with longer cooking times tend to include combinations of vegetables, proteins, and carbohydrates in recommended proportions. On the other hand, shorter cooking time recipes may favor convenience, potentially leading to less nutritionally balanced options like single-ingredient meals. Since we are specifically interested in whether one group tended to outperform the other rather than simply checking for any difference, we have a <strong>directional hypothesis</strong> (higher balance scores for long cooking times), therefore leading to the choice of test statistic, difference in means.</p>

<iframe src="assets/hyp_emp.html" width="800" height="600" frameborder="0"></iframe>

<p>We conducted a <strong>permutation test</strong> to determine if recipes with long cooking times have significantly higher balance scores than those with short cooking times. First, we calculated the observed difference in mean balance scores between the two groups, which is 0.01567. Then, we simulated the null hypothesis by shuffling the cooking time labels (long or short) across the dataset and recalculating the mean difference 1,000 times to build a null distribution. Finally, we calculated the p-value and got 0.0.</p>

<h3 id="conclusion-of-permutation-test">Conclusion of permutation test</h3>

<p>Since the p-value is <strong>0.0,</strong> it is less than the significance level of 0.05, therefore <strong>we reject the null hypothesis</strong>. Based on these results, we have strong evidence to suggest that <strong>recipes with longer cooking times tend to be more nutritionally balanced compared to shorter cooking time recipes</strong>. A <strong>plausible explanation</strong> for this finding could be that recipes with longer cooking times often involve more complex preparation methods or a greater variety of ingredients. However, this conclusion is drawn from a statistical test and should not be interpreted as absolute proof, as there could be other confounding factors influencing this relationship.</p>

<hr />

<h2 id="framing-a-prediction-problem">Framing a Prediction Problem</h2>

<p>This project is formulated as a <strong>binary classification problem</strong>, where the goal is to predict whether a recipe falls into the short or long cooking time category based on its nutritional composition and preparation complexity. Given that cooking time is categorical, classification is a more suitable approach than regression.</p>

<p>To define the response variable, <code class="language-plaintext highlighter-rouge">cooking_time_category</code>, we used the mean cooking time after removing outliers (36.7 minutes) as the threshold. Recipes with a cooking time below 36.7 minutes were labeled short, while those above were classified as long. The mean was chosen as the threshold because it provides a balanced split of the data, ensuring that both short and long cooking time categories are well-represented. Using the mean rather than an arbitrary cutoff allows for a <strong>data-driven classification</strong> that reflects the natural distribution of cooking times.</p>

<p>For <strong>model evaluation</strong>, we selected <strong>F1-score</strong> as our primary metric. Since some imbalance may exist between short and long cooking time categories, F1-score offers a more reliable assessment than accuracy by considering both precision and recall, preventing the model from favoring one class disproportionately.</p>

<p>At the time of prediction, all features used in the model—such as macronutrient proportions, total calories, sodium, sugar, fat content, and the number of preparation steps—are available before cooking begins. This ensures that the model only relies on information that would be realistically accessible when deciding how long a recipe is likely to take.
By structuring this as a classification problem with a threshold-based approach, this study aims to uncover patterns in cooking duration and provide insights into how nutrition and preparation complexity influence meal planning.</p>

<hr />

<h2 id="baseline-model">Baseline Model</h2>

<p>For our baseline model, we implemented a <strong>Logistic Regression classifier</strong> to predict whether a recipe falls into the short or long cooking time category. The model utilized two features: balance score and calories, both of which underwent preprocessing before being fed into the model.</p>
<ul>
  <li><strong>Balance score</strong> is a continuous quantitative feature that measures how closely a recipe’s macronutrient proportions (carbohydrates, fat, and protein) align with an ideal distribution.</li>
  <li><strong>Calories</strong> is a quantitative feature that we transformed into a nominal (binary) variable using a Binarizer with a 700-calorie threshold. Recipes with ≤ 700 calories were labeled as low-calorie (0), while those &gt; 700 calories were labeled as high-calorie (1).</li>
</ul>

<p>We applied an <strong>sklearn Pipeline</strong> for preprocessing:</p>
<ul>
  <li><strong>Binarizer</strong> converted calories into a categorical variable.</li>
  <li><strong>StandardScaler</strong> normalized the balance score for consistency.</li>
</ul>

<p>The dataset was then split into <strong>80% training and 20% testing</strong> to ensure model generalizability.</p>

<p>We assessed model performance using <strong>F1-score</strong> as the primary metric, as it balances precision and recall, making it more informative than accuracy when class imbalance is present. The overall F1-score was <strong>0.235</strong> (rounded), indicating weak classification performance.</p>

<p>The confusion matrix below shows that the model favors predicting short cooking times, correctly classifying 22,500 short recipes but misclassifying 14,790 long recipes as short. This imbalance results in poor recall for long recipes, as only 2,596 were correctly identified.</p>

<iframe src="assets/baseline_cf_matrix.html" width="800" height="600" frameborder="0"></iframe>

<p>Although the baseline model establishes a benchmark, its <strong>low F1-score</strong> (0.235) suggests that balance score and calories alone do not provide enough information to distinguish short vs. long cooking times effectively. The model is heavily biased toward predicting shorter cooking times, leading to poor recall for long recipes. This highlights the need for additional features—such as recipe complexity indicators (e.g., number of steps, ingredient count)—to enhance predictive performance and improve classification balance.</p>

<hr />

<h2 id="final-model">Final Model</h2>

<p>For our final model, we built upon the baseline Logistic Regression classifier by incorporating <strong>additional features</strong> and applying <strong>hyperparameter tuning</strong> to improve predictive performance. The objective remained the same: to classify recipes into short or long cooking times, but with a more refined approach that leveraged both nutritional composition and procedural complexity. 
The final model used <code class="language-plaintext highlighter-rouge">balance_score</code>, <code class="language-plaintext highlighter-rouge">sodium</code>, <code class="language-plaintext highlighter-rouge">sugar</code>, <code class="language-plaintext highlighter-rouge">saturated_fat</code>, <code class="language-plaintext highlighter-rouge">total_fat</code>, <code class="language-plaintext highlighter-rouge">calories</code>, and <code class="language-plaintext highlighter-rouge">n_steps</code> as features to predict the cooking time category.</p>

<p><strong>Features</strong></p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">balance_score</code>
    <ul>
      <li>The balance score measures how closely a recipe’s macronutrient proportions (carbohydrates, protein, and fat) align with an ideal distribution. The ‘Distribution of Balance Scores by Cooking Time Category’ histogram shows that while short and long-cooking recipes have similar balance score distributions, <strong>long-cooking recipes exhibit slightly greater variation</strong>. This suggests that recipes with diverse macronutrient compositions tend to have longer cooking times, likely due to <strong>increased complexity</strong> and multi-step preparation. Thus, balance score is a <strong>valuable predictor</strong> of cooking duration.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">sodium</code>, <code class="language-plaintext highlighter-rouge">sugar</code>, <code class="language-plaintext highlighter-rouge">saturated_fat</code>, <code class="language-plaintext highlighter-rouge">total_fat</code>
    <ul>
      <li>These macronutrient-related features were <strong>not included</strong> in the calculation of <code class="language-plaintext highlighter-rouge">balance_score</code>, but provide additional insights into recipe complexity and ingredient composition. Nutritional content often correlates with recipe complexity, as more complex recipes (e.g., baked goods or slow-cooked meals) tend to involve ingredients that contribute to higher levels of sugar, fat, or sodium. These features provide <strong>fine-grained detail</strong> about the recipes, helping us gauge how ingredient composition influences cooking duration.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">calories</code>
    <ul>
      <li>Calories often indicate the <strong>overall composition of a recipe</strong>, with higher-calorie dishes frequently associated with longer cooking times. To enhance predictive power, we applied a Binarizer to classify recipes into “low-calorie” and “high-calorie” categories, <strong>tuning the threshold</strong> to 500 calories instead of 700 calories, as used in the baseline model.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">n_steps</code>
    <ul>
      <li>The number of steps in a recipe is a <strong>strong indicator of complexity</strong>, with multi-step processes often requiring longer preparation times. The ‘Distribution of Number of Steps by Cooking Time Category’ histogram shows that while both short and long-cooking recipes follow a right-skewed distribution, <strong>long-cooking recipes tend to have more steps on average</strong>. This suggests that intricate recipes with more steps, such as casseroles, pastries, or braised dishes, are more likely to fall into the long cooking time category. By incorporating this feature, our model gains a clearer distinction between simpler and more complex recipes, <strong>improving</strong> its ability to accurately predict cooking time categories.</li>
    </ul>
  </li>
</ol>

<p><strong>Preprocessing steps</strong></p>
<ol>
  <li><strong>StandardScaler</strong> for <code class="language-plaintext highlighter-rouge">sodium</code>, <code class="language-plaintext highlighter-rouge">sugar</code>, <code class="language-plaintext highlighter-rouge">saturated_fat</code>, and <code class="language-plaintext highlighter-rouge">total_fat</code>:
These features contain potential outliers. So, standardization ensures they are scaled consistently, helping the model avoid being biased toward features with larger ranges.</li>
  <li><strong>Binarizer</strong> for <code class="language-plaintext highlighter-rouge">calories</code>:
The threshold for binarization was tuned to <strong>500</strong> during hyperparameter selection, ensuring that the calorie split aligns with meaningful calorie boundaries in the dataset.</li>
  <li><strong>QuantileTransformer</strong> for <code class="language-plaintext highlighter-rouge">balance_score</code>:
This hyperparameter controls the number of quantile divisions applied to the balance_score. Different numbers of quantiles can better handle varying levels of skew or data granularity, depending on the dataset. By tuning this, we ensure the transformation aligns optimally with the data’s characteristics. Transforming balance_score with <strong>200</strong> quantiles addressed any skewness in its distribution, enabling the model to better utilize this continuous feature.</li>
  <li><strong>Pass-through</strong> for <code class="language-plaintext highlighter-rouge">n_steps</code>:
This feature was kept unchanged, as its numeric values naturally reflect recipe complexity.</li>
</ol>

<p><strong>Modeling Algorithm</strong>
We chose <strong>Logistic Regression</strong> as our modeling algorithm as our prediction problem is a binary classification. Logistic Regression is also computationally efficient, making it well-suited for this task. To enhance performance, we used <strong>GridSearchCV</strong> with 5-fold cross validation to tune both preprocessing parameters and model hyperparameters. The <strong>F1-score</strong> was used as the scoring metric to ensure balance between precision and recall.</p>

<p><strong>Hyperparameter Tuning Results</strong></p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">preprocessor__quantile__n_quantiles</code>: 200
    <ul>
      <li>A high number of quantiles allowed the model to capture the fine-grained distribution of balance_score, thus handling skews more efficiently.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">preprocessor__binarizer__threshold</code>: 500
    <ul>
      <li>A lower calorie threshold (500) was optimal for distinguishing recipes based on their complexity and duration.
Classifier Hyperparameters:</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">classifier</code>__C = 0.01
    <ul>
      <li>This low regularization strength provided better generalization and is ideal to prevent overfitting.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">classifier__penalty</code> = ‘l2’
    <ul>
      <li>L2 regularization smoothed the model’s weights helping it perform consistently across both classes.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">classifier__solver</code> = ‘liblinear’
    <ul>
      <li>liblinear is ideal for datasets with limited features or smaller datasets.</li>
    </ul>
  </li>
</ol>

<p><strong>Performance Comparison</strong></p>

<p>Comparing the confusion matrices for the baseline and final model, the baseline model heavily favored predicting “short” cooking times, leading to <strong>poor recall</strong> for “long” recipes, as it only correctly classified 2,596 “long” labels while misclassifying 14,790 as “short.” In contrast, the final model significantly <strong>improved recall</strong> for “long” recipes, correctly identifying 14,585 and reducing misclassifications to 2,801. Although this improvement led to more false positives for “short” recipes (increasing from 2,124 to 13,176), it resulted in a more <strong>balanced classification</strong> overall as seen by the final model’s F1 score.</p>

<iframe src="assets/conf_matrix.html" width="800" height="600" frameborder="0"></iframe>

<p>The metric <strong>F1 score</strong> of the final model is <strong>0.531</strong>(rounded), which is a <strong>0.3 increase</strong> from the F1 score of the base model. The final model significantly improved over the baseline by incorporating additional features and using hyperparameter tuning to refine both preprocessing and classification. By leveraging meaningful recipe attributes, such as the number of steps and nutritional content, the model effectively captured the nuances of cooking durations. The final F1-score showcases the impact of these enhancements, making the model much more reliable for predicting short versus long cooking times.</p>

<hr />

<h2 id="fairness-analysis">Fairness Analysis</h2>
<p>For our fairness analysis, we split the recipes into two groups: <strong>high rating recipes and low rating recipes</strong>. High-rating recipes are defined as recipes with a rating greater than or equal to the median rating of the dataset, while low-rating recipes have a rating below the median. We selected <strong>2.5</strong> as the threshold for ratings since the rating scale ranges from 1 to 5, and 2.5 represents the midpoint, providing an even split for categorizing recipes as either highly or lowly rated.</p>

<p>We evaluate the <strong>precision parity</strong> of the model for these two groups because precision reflects the model’s ability to correctly identify cooking time category (short or long) without mislabeling. Precision is particularly <strong>important</strong> to minimize false positives, which could mislead users about cooking times for recipes, impacting their decisions or experiences. For example, if a low-rated recipe is incorrectly predicted as having a long cooking time, users might avoid it unnecessarily.</p>

<p><ins><strong>Null Hypothesis</strong></ins>: Our model is fair. Its precision for high rating and low rating recipes are roughly the same, and any differences are due to random chance.</p>

<p><ins><strong>Alternate Hypothesis</strong></ins>: Our model is unfair. Its precision for low rating recipes is significantly lower than its precision for high rating recipes.</p>

<p><ins><strong>Test Statistic</strong></ins>: The difference in precision between the two groups: (low rating - high rating)</p>

<p><ins><strong>Significance Level</strong></ins>: 0.05</p>

<p>To run the permutation test, first, we split the data into two groups based on the rating threshold of 2.5, categorizing recipes as either “High” or “Low” rated. We calculated the observed precision difference between these two groups <strong>(Low - High)</strong>. To simulate the null hypothesis, we randomly shuffled the rating categories 1,000 times while keeping the true labels and predictions fixed. For each permutation, we recalculated the precision difference to generate a null distribution. Finally, we compared the observed precision difference, which was <strong>0.0401</strong>, to the null distribution to compute the p-value.</p>

<iframe src="assets/fair_emp.html" width="800" height="600" frameborder="0"></iframe>
<p>With a p-value of <strong>0.003</strong>, which is significantly less than the chosen significance level of 0.05, <strong>we reject the null hypothesis</strong>. This suggests that there is evidence of a <strong>disparity in precision</strong>, where the model performs <strong>less effectively</strong> for low-rated recipes compared to high-rated ones.</p>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>In this project, we developed a classification model to predict whether a recipe falls into the short or long cooking time category, using <strong>nutritional composition and procedural complexity</strong> as key predictors. Our baseline <strong>Logistic Regression model</strong>, relying only on <code class="language-plaintext highlighter-rouge">balance_score</code> and <code class="language-plaintext highlighter-rouge">calories</code>, struggled to distinguish between the two categories, achieving an <strong>F1-score of 0.235</strong>, with poor recall for long recipes.</p>

<p>To improve performance, we incorporated <code class="language-plaintext highlighter-rouge">sodium</code>, <code class="language-plaintext highlighter-rouge">sugar</code>, <code class="language-plaintext highlighter-rouge">saturated_fat</code>, <code class="language-plaintext highlighter-rouge">total_fat</code>, and <code class="language-plaintext highlighter-rouge">n_steps</code>, capturing both ingredient composition and recipe complexity. <strong>Exploratory data analysis</strong> supported these choices, showing that <code class="language-plaintext highlighter-rouge">n_steps</code> strongly correlated with longer cooking times, while sodium, sugar, and fat content acted as indicators of ingredient-driven complexity. <strong>Preprocessing steps</strong>, including <strong>Quantile Transformation</strong> for <code class="language-plaintext highlighter-rouge">balance_score</code>, <strong>Standard Scaling</strong> for macronutrients, and <strong>Binarization</strong> for <code class="language-plaintext highlighter-rouge">calories</code> with an optimized 500-calorie threshold, helped normalize the data. <strong>GridSearchCV with 5-fold cross-validation</strong> further optimized model performance.</p>

<p>These refinements significantly improved classification, raising the <strong>final F1-score to 0.531</strong>, more than <strong>double</strong> the baseline model’s performance. The improved recall for long-cooking recipes suggests that recipes with greater macronutrient variation, higher sodium and fat content, and more preparation steps are more likely to require longer cooking times. This confirms that <strong>both nutritional composition and procedural complexity are key factors influencing cooking duration</strong>.</p>

<p>Ultimately, our model provides <strong>meaningful insight into how a recipe’s attributes relate to cooking time</strong>, highlighting patterns that could inform recipe planning, meal recommendations, or even automated cooking assistance. This study demonstrates the power of integrating both nutritional and procedural data to make informed predictions about cooking duration, reinforcing the idea that complexity—whether in ingredients or steps—is a strong determinant of preparation time.</p>

<hr />


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/NandaPayy/Recipe_Project">Recipe_Project</a> is maintained by <a href="https://github.com/NandaPayy">NandaPayy</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
